{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5 演習01 MNISTの多クラス分類\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本演習では、手書き数字のMNISTをRNNを用いて分類します。\n",
    "\n",
    "**はじめに**\n",
    "- for文やwhile文の利用は明示的な利用指示がない場所での利用は避けてください。\n",
    "\n",
    "**本演習の目的**\n",
    "- RNNをNumPyのみで実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインストール\n",
    "\n",
    "まずはじめに、本演習で利用するライブラリのインポートを行います。\n",
    "\n",
    "- [numpy](http://www.numpy.org) 数値計算を行うための基本パッケージの公式ドキュメント\n",
    "- [matplotlib](http://matplotlib.org) グラフ描画ライブラリの基本パッケージの公式ドキュメント\n",
    "- [tensorflow](https://www.tensorflow.org/) 機械学習用のライブラリの公式ドキュメント\n",
    "\n",
    "\n",
    "`%matplotlib inline` はnotebook上で使える[magic function](http://ipython.readthedocs.io/en/stable/interactive/magics.html)の一つで、これによりmatplotlibをインタラクティブに使うことできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット\n",
    "まずMNISTデータ・セットを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# データの読み込み\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", \n",
    "                                  one_hot=True, \n",
    "                                  validation_size=0)\n",
    "\n",
    "# データのシャッフル\n",
    "permutation = np.random.permutation(mnist.train._images.shape[0])\n",
    "mnist.train._images = mnist.train.images[permutation]\n",
    "mnist.train._labels = mnist.train.labels[permutation]\n",
    "\n",
    "#データの正規化\n",
    "mean = np.mean(mnist.train.images)\n",
    "std = np.std(mnist.train.images)\n",
    "mnist.train._images = (mnist.train.images-mean)/std\n",
    "mnist.test._images = (mnist.test.images-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この演習ではMNISTの画像を行毎にシーケンスデータとしてRNNにいれます。（数字の８の例です）\n",
    "\n",
    "<img src=\"./img/step5_mnist_sequence.png\" width=\"620\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/step5_mnist.gif\" width=\"240\" height=\"240\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML #HTMLをセル内で書くことのできるようにするmagic functionです\n",
    "<img src=\"img/step5_mnist.gif\" width=\"240\" height=\"240\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルパラメータの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は下記のモデルパラメータを用います。隠れ層は100付近の値に設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 100 # 隠れ層のサイズ\n",
    "image_size = 28 # 入力画像のサイズ\n",
    "class_num = 10 #　分類するカテゴリ数（0~9）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの重みの初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題１】**　RNNのパラメータと勾配そしてAdamを使用する際に必要なパラメータを初期化します。\n",
    "\n",
    "ここではモデルのパラメータをCNNのときと同様に[glorot_uniform](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)で初期化します。バイアスはゼロで初期化します。numpyでの一様分布生成には[np.random.uniform](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.uniform.html)を用います。また、[np.zeros](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.zeros.html)を用いてゼロの配列を生成します。\n",
    "\n",
    "\n",
    "[\"glorot_uniform\"](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "$$\\pm\\sqrt{\\frac{6}{(input\\_channel+ output\\_channel)}}$$\n",
    "\n",
    "この演習では[Adam](https://arxiv.org/pdf/1412.6980.pdf)を使ってRNNを学習させてみます。それにあたり、いくつかの配列を用意します。これらは重みと同じ形をしたゼロの配列で初期化します。これには[np.zeros_like](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html)を用います。\n",
    "\n",
    "`init_parameters`の最後では重みのパラメータとAdamに必要なパラメータをまとめて返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber1 3edc123b66020b7fbe6053158fdead12\n",
    "def init_parameters(image_size, hidden_size, class_num):\n",
    "    ###############START CODE HERE###############\n",
    "    #入力から隠れ層の重み（入力サイズ、隠れ層のユニット数）\n",
    "    std1 = np.sqrt(6 / (image_size + hidden_size))\n",
    "    U = np.random.uniform(low = -std1, high = +std1, size = (image_size, hidden_size))\n",
    "\n",
    "    #隠れ層から隠れ層の重み（隠れ層のユニット数、隠れ層のユニット数）\n",
    "    std2 = np.sqrt(6 / (hidden_size + hidden_size))\n",
    "    W = np.random.uniform(low = -std2, high = +std2, size = (hidden_size, hidden_size))\n",
    "\n",
    "    #隠れ層から出力層の重み（隠れ層のユニット数、クラス数）\n",
    "    std3 = np.sqrt(6 / (hidden_size + class_num))\n",
    "    V = np.random.uniform(low = -std3, high = std3, size = (hidden_size, class_num))\n",
    "\n",
    "    # 隠れ層のバイアス（1, 隠れ層のユニット数）\n",
    "    b = np.zeros((1, hidden_size))\n",
    "    # 出力層のバイアス（1, クラス数）\n",
    "    c = np.zeros((1, class_num))\n",
    "\n",
    "    # Adamを使用するにあたって必要なパラメータの初期化\n",
    "    mU, mW, mV = np.zeros_like(U), np.zeros_like(W), np.zeros_like(V)\n",
    "    mb, mc =  np.zeros_like(b), np.zeros_like(c)\n",
    "    vU, vW, vV =np.zeros_like(U), np.zeros_like(W), np.zeros_like(V)\n",
    "    vb, vc = np.zeros_like(b), np.zeros_like(c)\n",
    "    \n",
    "    ################END CODE HERE################\n",
    "    \n",
    "    # パラメータをタプルにまとめます。\n",
    "    params = (U, W, V, b, c)\n",
    "    ms = (mU, mW, mV, mb, mc)\n",
    "    vs = (vU, vW, vV, vb, vc)\n",
    "    return params, ms, vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 1 Step5_01.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フォワードプロパゲーションの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題２】**　ここではRNNの順伝播を実装します。\n",
    "\n",
    "RNNのフォワードプロパゲーションは教材のスライドでは以下のように書きました。\n",
    "\n",
    "\n",
    "** フォワードプロパゲーション（ミニバッチの次元がないとき） **\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\boldsymbol{a}{(t)}&=&\\boldsymbol{b}+\\boldsymbol{Wh}{(t-1)}+\\boldsymbol{Ux}{(t)}\\\\\n",
    "\\boldsymbol{h}{(t)}&=&tanh(\\boldsymbol{a}{(t)})\\\\\n",
    "\\boldsymbol{o}{(t)}&=&\\boldsymbol{c}+\\boldsymbol{Vh}{(t)}\\\\\n",
    "\\boldsymbol{\\hat{y}}{(t)}&=&softmax(\\boldsymbol{o}{(t)})\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "しかしながら、実装する際は少し書き方を以下のように改める必用があります。これは、$\\boldsymbol{x}$にはバッチの次元があり上記通りに実装すると計算ができないからです。例えば$\\boldsymbol{Ux}^{(t)}$を計算するときに$\\boldsymbol{U}=(image\\_size, hidden\\_size)$,  $\\boldsymbol{x}=(batch\\_size, image\\_size)$となっているので計算ができません。（numpyのブロードキャスト機能を使いたい）なので、以下のように式を変更します。\n",
    "\n",
    "** フォワードプロパゲーション（ミニバッチの次元があるとき） **\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\boldsymbol{a}{(t)}&=&\\boldsymbol{b}+\\boldsymbol{h}{(t-1)}\\boldsymbol{W}+\\boldsymbol{x}{(t)}\\boldsymbol{U}\\\\\n",
    "\\boldsymbol{h}{(t)}&=&tanh(\\boldsymbol{a}{(t)})\\\\\n",
    "\\boldsymbol{o}{(t)}&=&\\boldsymbol{c}+\\boldsymbol{h}{(t)}\\boldsymbol{V}\\\\\n",
    "\\boldsymbol{\\hat{y}}{(t)}&=&softmax(\\boldsymbol{o}{(t)})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "`forward_propagation`には4つの引数があります。\n",
    "- `X`: 入力画像（バッチサイズ、縦×横）\n",
    "- `params`: `init_parameters`で用意した重みとバイアス\n",
    "- `batch_size`: バッチサイズ\n",
    "- `hidden_size`: 隠れ層のサイズ\n",
    "\n",
    "この関数内では、\n",
    "- `params`から重みとバイアスを取り出します。\n",
    "- `h`: 隠れ層の値（上の式でいう$\\boldsymbol{h}$）を記録するために空の辞書を用意します。\n",
    "- `h[-1]`: フォワードプロパゲーションの１ステップに必要な値（ゼロ）をいれます。\n",
    "- 入力`X`の形を（バッチサイズ、縦×横）から（バッチサイズ、縦、横）に変更します。\n",
    "- forループで画像の行数分（２８）回します。ループ内では毎回、入力画像の1行分を（$\\boldsymbol{x}^{(t)}$）としていれます。ここではまだ`X`は画像全体なので注意して扱ってください。ループさせる次元は入力画像の行成分なので、初めのループではX[:,0]となります。\n",
    "- `y_pred`: `o`にソフトマックス関数を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber2 6604f8fa48941ea591de1f55d5308a70\n",
    "def softmax(x, axis=1):\n",
    "    exp_x = np.exp(x)\n",
    "    y = exp_x / np.sum(exp_x, axis=axis, keepdims=True) \n",
    "    return y\n",
    "\n",
    "def forward_propagation(X, params, batch_size, hidden_size):\n",
    "    U, W, V, b, c = params\n",
    "    h = {}\n",
    "    h[-1] = np.zeros((batch_size, hidden_size))\n",
    "    X = X.reshape(-1, 28, 28)\n",
    "    ###############START CODE HERE###############\n",
    "    for t in range(28):\n",
    "        a = b + np.dot(h[t-1], W) + np.dot(X[:, t], U)\n",
    "        h[t] = np.tanh(a)\n",
    "    o = c + np.dot(h[t], V)\n",
    "    # ソフトマックス関数\n",
    "    y_pred =softmax(o)\n",
    "    ################END CODE HERE################\n",
    "    return y_pred, X, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 2 Step5_01.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コスト関数の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題３】**　ここではコスト関数を実装します。\n",
    "\n",
    "\n",
    "コスト関数には交差エントロピーを使います。\n",
    "$$\n",
    "cost = - \\frac{1}{m}\\sum_x y(x) \\log{\\hat{y}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber3 758ca7378619b92e6251f1cabf54ebf7\n",
    "def compute_cost(y_pred, targets, batch_size):\n",
    "    ###############START CODE HERE###############\n",
    "    cost = -np.sum(np.log(y_pred)*targets)/float(batch_size)\n",
    "    ################END CODE HERE################\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 3 Step5_01.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpyの仕様"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyには少し変わった仕様があります。通常forループで配列の要素（これもまたnp.ndarray)を取り出しそれを変更してももとの配列は変更されません(`test1`の例)。しかしながら、`test2`の例 で`j += 1`のように書くと元の配列の中身が変更されます。注意しなければならないのはこれはforループで取り出される要素がnp.ndarrayの場合です。なので`test3`の例では値は変更されていません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1[[1 2]]\n",
      "test2[[1 2]]\n",
      "test3[1 2]\n",
      "test1[[1 2]]\n",
      "test2[[2 3]]\n",
      "test3[1 2]\n"
     ]
    }
   ],
   "source": [
    "test1 = np.array([[1,2]])\n",
    "test2 = np.array([[1,2]])\n",
    "test3 = np.array([1,2])\n",
    "print('test1{}'.format(test1))\n",
    "print('test2{}'.format(test2))\n",
    "print('test3{}'.format(test3))\n",
    "for i, j, k in zip(test1, test2, test3):\n",
    "    i = i + 1\n",
    "    j += 1\n",
    "    k += 1\n",
    "print('test1{}'.format(test1))\n",
    "print('test2{}'.format(test2))\n",
    "print('test3{}'.format(test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バックプロパゲーションの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題４】**　ここでは通時的誤差逆伝播法（back-propagation through time, BPTT)を実装します。\n",
    "\n",
    "この演習で実装するのは以下のようなRNNで出力は一番最後にしかありません。\n",
    "<img src=\"./img/step5_bptt.png\" width=\"360\" height=\"120\">\n",
    "\n",
    "\n",
    "`backward_propagation`は5つの引数があります。\n",
    "- `params`: `init_parameters`で用意した重みとバイアス\n",
    "- `X`: 入力画像（バッチサイズ、縦×横）\n",
    "- `h`: フォワード時の隠れ状態\n",
    "- `y_pred`:  フォワード時の出力結果\n",
    "- `targets`: 正解ラベル\n",
    "\n",
    "この関数内では、\n",
    "- `params`から重みとバイアスを取り出します。\n",
    "- 勾配を入れるための配列を作成します。\n",
    "\n",
    "- forループで画像の行数分（２８）回します。ここでは図で言う右上（出力）から伝播させて行くので`reversed`させます。これにより[0, 1, ..., 27]が[27, ..., 1, 0]となります。\n",
    "- パラメータ`V`と`c`があるのはt==27の時のみなので、ここでまず、$\\frac{\\partial C}{\\partial \\boldsymbol{o}}$を求めます。この演習ではsoftmaxと交差エントロピーを使っているので単純に予測ラベルー正解ラベルになります。\n",
    "\n",
    "ここでは時刻tがあるので少しややこしいとは思いますが、ニューラルネットワークの時の計算を参考にすれば書けるはずです。**注意**RNNではコスト関数を最後、データ長（seq_length, この演習の場合28）で割る必要があります。よって、逆伝播時も`delta_o`をデータ長割ります。\n",
    "\n",
    "最後に勾配爆発が起こらないように勾配クリッピングをします。今回は勾配が-1から1の範囲の値を取るように制限します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber4 ffa1f4b4e9e6d0f0436cdeae38d22256\n",
    "def backward_propagation(params, X, h, y_pred, targets):\n",
    "    #パラメータの取り出し\n",
    "    U, W, V, b, c = params\n",
    "    batch_size, seq_length = X.shape[:2]\n",
    "    # 勾配を入れるための配列の作成\n",
    "    delta_U, delta_W, delta_V = np.zeros_like(U), np.zeros_like(W), np.zeros_like(V)\n",
    "    delta_b, delta_c = np.zeros_like(b), np.zeros_like(c)\n",
    "    delta_h_next = np.zeros_like(h[0]) # h(t-1)の勾配\n",
    "    for t in reversed(range(28)):\n",
    "        ###############START CODE HERE###############\n",
    "        if t == 27:\n",
    "            # ソフトマックスと交差エントロピーの逆伝播, dC/do\n",
    "            delta_o = (y_pred - targets) / float(batch_size)\n",
    "            delta_o /= seq_length\n",
    "            # dC/dv = do/dV.T * dC/do\n",
    "            delta_V += np.dot(h[t].T, delta_o)\n",
    "            # dC/dc = do/dc * dC/do = dC/do, バッチ次元で足し合わせる\n",
    "            delta_c += np.sum(delta_o, axis = 0)\n",
    "            # dC/dh = dC/do * do/dh.T\n",
    "            delta_h = np.dot(delta_o, V.T)\n",
    "        else:\n",
    "            delta_h = delta_h_next\n",
    "        # dC/da = dh/da * dC/dh(t), tanh(x)の勾配は1-tanh^2(x)\n",
    "        delta_a = (1 - h[t]*h[t]) * delta_h\n",
    "        # dC/db = da/db * dC/da = dC/da\n",
    "        delta_b += np.sum(delta_a, axis = 0)\n",
    "        # dC/dU = da/dU.T * dC/da\n",
    "        delta_U += np.dot(X[:,t].T, delta_a)\n",
    "        # dC/dW = da/dW.T * dC/da\n",
    "        delta_W += np.dot(h[t-1].T, delta_a)\n",
    "        # dC/dh_next = dC/da * da/dh(t-1).T\n",
    "        delta_h_next =np.dot(delta_a, W.T)\n",
    "        ################END CODE HERE################\n",
    "    grads = (delta_U, delta_W, delta_V, delta_b, delta_c)\n",
    "    # 勾配クリッピング\n",
    "    for g in grads:\n",
    "        np.clip(g, -1, 1, out=g)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 4 Step5_01.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題５】**　ADAMを実装します。\n",
    "\n",
    "ここでは[ADAM](https://arxiv.org/pdf/1412.6980.pdf)でパラメータを更新します。\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\boldsymbol{m}_t &=& \\beta_1 \\boldsymbol{m}_{(t-1)} + (1-\\beta_1)\\boldsymbol{g}_t\\\\\n",
    "\\boldsymbol{v}_t &=& \\beta_2 \\boldsymbol{v}_{(t-1)} + (1-\\beta_2)\\boldsymbol{g}_t^2\\\\\n",
    "\\boldsymbol{\\hat{m}}_t &=& \\frac{\\boldsymbol{m}_t}{(1-\\beta_1^t)}\\\\\n",
    "\\boldsymbol{\\hat{v}}_t &=& \\frac{\\boldsymbol{v}_t}{(1-\\beta_2^t)}\\\\\n",
    "\\boldsymbol{p}_t &=& \\boldsymbol{p}_{(t-1)} - \\alpha \\frac{\\boldsymbol{\\hat{m}_t}}{\\sqrt{\\boldsymbol{\\hat{v}}_t}+\\epsilon}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "`update_parameters`は5つの引数があります。\n",
    "- `params`: 重みとバイアス\n",
    "- `grads`: 勾配\n",
    "- `ms`, `vs`: ADAMを使って必要な値\n",
    "- `iteration`: 現在のステップ数 `t`（ADAMのbias correction）\n",
    "- `num`: ここでは、len(params)=5をforループで回している。（paramsにはU, W, V, b, cの5つのパラメータがタプルで格納されている。）例：params[0] はU、grads[0]はUの勾配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber5 feb5efc7f144a5a1dba1a0490b7c683c\n",
    "def update_parameters(params, grads, ms, vs, iteration):\n",
    "    alpha = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps = 1e-8\n",
    "    for num in range(len(params)):\n",
    "        p, g, m, v = params[num], grads[num], ms[num], vs[num]\n",
    "        ###############START CODE HERE###############\n",
    "        # Adam\n",
    "        m_t = beta1 * m + (1 - beta1) * g\n",
    "        v_t = beta2 * v + (1 - beta2) * g * g\n",
    "        m_t_hat = m_t / (1 - np.power(beta1, iteration))\n",
    "        v_t_hat = v_t / (1 - np.power(beta2, iteration))\n",
    "        params[num][:] = p - alpha * m_t_hat / (np.sqrt(v_t_hat) + eps)\n",
    "        ################END CODE HERE################\n",
    "        ms[num][:] = m_t\n",
    "        vs[num][:] = v_t\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 5 Step5_01.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNの学習\n",
    "作成したRNNをデータセットで学習させます。本来であれば数十エポック学習させるのですが、時間がかかってしまうのでここでは5エポック学習させます。これでも十分な精度がでるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t iter: 230, cost: 0.080, acc: 0.160\n",
      "0: epoch, cost: 0.082, acc: 0.150\n",
      " \t iter: 230, cost: 0.060, acc: 0.292\n",
      "1: epoch, cost: 0.068, acc: 0.270\n",
      " \t iter: 230, cost: 0.084, acc: 0.116\n",
      "2: epoch, cost: 0.071, acc: 0.255\n",
      " \t iter: 230, cost: 0.082, acc: 0.108\n",
      "3: epoch, cost: 0.083, acc: 0.100\n",
      " \t iter: 230, cost: 0.082, acc: 0.104\n",
      "4: epoch, cost: 0.082, acc: 0.104\n",
      "CPU times: user 1min 51s, sys: 40.6 s, total: 2min 32s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# バッチサイズ\n",
    "batch_size = 250\n",
    "# １エポックあたりのステップ数\n",
    "total_step_train = int(len(mnist.train.labels)/batch_size)\n",
    "# パラメータの初期化\n",
    "params, ms, vs = init_parameters(image_size, hidden_size, class_num)\n",
    "# ロス/精度を記録するための配列\n",
    "train_cost = []\n",
    "train_acc = []\n",
    "for epoch in range(5): #5エポック学習\n",
    "    for iteration in range(total_step_train):\n",
    "        inputs, targets = mnist.train.next_batch(batch_size, fake_data=False)\n",
    "        # 順伝播\n",
    "        y_pred, X, h = forward_propagation(inputs, params, batch_size, hidden_size)\n",
    "        # コスト関数\n",
    "        _cost = compute_cost(y_pred, targets, batch_size) / X.shape[1]\n",
    "        # 逆伝播\n",
    "        grads = backward_propagation(params, X, h, y_pred, targets)\n",
    "        # パラメータのアップデート\n",
    "        params = update_parameters(params, grads, ms, vs, total_step_train*epoch+iteration+1)\n",
    "        \n",
    "        assert not np.isnan(_cost), 'nan in cost'\n",
    "        # accuracyとcostを記録\n",
    "        _acc = np.mean(np.argmax(y_pred, axis=1)==np.argmax(targets, axis=1))\n",
    "        # ログをプリント\n",
    "        if iteration % 10 == 0:\n",
    "            print('\\r \\t iter: {}, cost: {:.3f}, acc: {:.3f}'.format(iteration, _cost, _acc), end='')\n",
    "        train_cost.append(_cost)\n",
    "        train_acc.append(_acc)\n",
    "    # このエポックの平均ロスと精度をプリント\n",
    "    print('\\n{}: epoch, cost: {:.3f}, acc: {:.3f}'.format(epoch, \n",
    "                                                          np.mean(train_cost[total_step_train*epoch:]), \n",
    "                                                          np.mean(train_acc[total_step_train*epoch:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの精度とロスのプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データの精度とロスをプロットしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_cost)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Cost', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータの精度とロスの計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータの精度とロスを計算してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_cost = []\n",
    "test_acc = []\n",
    "inputs = mnist.test.images\n",
    "targets = mnist.test.labels\n",
    "batch_size = len(inputs)\n",
    "y_pred, x, h = forward_propagation(inputs, params, batch_size, hidden_size)\n",
    "# コスト関数\n",
    "_cost = compute_cost(y_pred, targets, batch_size)\n",
    "\n",
    "_acc = np.mean(np.argmax(y_pred, axis=1)==np.argmax(targets, axis=1))\n",
    "test_cost.append(_cost)\n",
    "test_acc.append(_acc)\n",
    "# ログをプリント\n",
    "print('cost: {:.3f}, acc: {:.3f}'.format(np.mean(test_cost), np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "最後にモデルの予測とそのときの入力データを確認してみます。セルを何度か実行し、確認してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(10000) #　ランダムな数を生成し、idxに格納\n",
    "print(\"モデルの予測：\", np.argmax(y_pred[idx]))#　idx番目のモデルの予測結果\n",
    "plt.imshow(inputs.reshape(10000, 28,28)[idx], cmap='gray')#　idx番目の入力データの画像を表示\n",
    "plt.title(\"Input Data\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "282px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
