{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5 演習07 LSTMとGRU\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本演習では、LSTMとGRUをスクラッチで実装します。\n",
    "\n",
    "**はじめに**\n",
    "- for文やwhile文の利用は明示的な利用指示がない場所での利用は避けてください。\n",
    "\n",
    "**本演習の目的**\n",
    "- LSTMとGRUのパラメータの数を理解する。\n",
    "- LSTMとGRUの順伝播を実装する。\n",
    "- Gradient Checkのコードを実装する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインストール\n",
    "\n",
    "まずはじめに、本演習で利用するライブラリのインポートを行います。\n",
    "\n",
    "- [numpy](http://www.numpy.org) 数値計算を行うための基本パッケージの公式ドキュメント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMとGRU両方で使う関数の準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いつもどおりglorot uniformで初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glorot_uniform(shape, seed=1234):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    if len(shape) == 2:\n",
    "        fan_in, fan_out = shape\n",
    "        std = np.sqrt(6./(fan_in+fan_out))\n",
    "        return rng.uniform(low=-std, high=std, size=(fan_in, fan_out))\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シグモイド関数とハイパボリックタンジェント関数を用意します。また、それぞれを微分した関数も用意します。ここで、`dsigmoid`や`dtanh`の引数はは既に`sigmoid`や`tanh`を計算した値とします。なので、ニューラルネットワークの章の演習とは少し異なります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "def dsigmoid(sigmoid_x):\n",
    "    return sigmoid_x * (1 - sigmoid_x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(tanh_x):\n",
    "    return (1-tanh_x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではここからLSTMの実装を行います。この演習では入力、出力、忘却ゲートはありますが、覗き穴結合はないタイプのLSTM（下図参照）を実装します。\n",
    "\n",
    "<img src=\"./img/step5_LSTM.png\" width=\"360\" height=\"120\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### LSTMのパラメータの初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "覗き穴結合がない場合、入力ゲート$\\boldsymbol{i}(t)$、出力ゲート$\\boldsymbol{o}(t)$、忘却ゲート$\\boldsymbol{f}(t)$そして、活性化関数$f$後の値$\\boldsymbol{a}(t)$は以下のようにして求められます。\n",
    "\n",
    "$$\n",
    "\\boldsymbol{i}(t)\n",
    "=\n",
    "\\sigma(\\boldsymbol{W_i} \\boldsymbol{x}(t) + \\boldsymbol{U_i} \\boldsymbol{h}(t-1) + \\boldsymbol{b}_i)\\tag{1.1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{o}(t)\n",
    "=\n",
    "\\sigma(\\boldsymbol{W_o} \\boldsymbol{x}(t) + \\boldsymbol{U_o} \\boldsymbol{h}(t-1) + \\boldsymbol{b}_o)\\tag{1.2}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{f}(t)\n",
    "=\n",
    "\\sigma(\\boldsymbol{W_f} \\boldsymbol{x}(t) + \\boldsymbol{U_f} \\boldsymbol{h}(t-1) + \\boldsymbol{b}_f)\\tag{1.3}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a}(t)\n",
    "=\n",
    "f(\\boldsymbol{W_a} \\boldsymbol{x}(t) + \\boldsymbol{U_a} \\boldsymbol{h}(t-1) + \\boldsymbol{b}_a)\\tag{1.4}\n",
    "$$\n",
    "\n",
    "ここで、これら４式の活性化関数内の部分をそれぞれ$\\boldsymbol{\\hat{i}}(t)$、$\\boldsymbol{\\hat{o}}(t)$、$\\boldsymbol{\\hat{f}}(t)$、$\\boldsymbol{\\hat{a}}(t)$、と置きます。なので例えば、$\\boldsymbol{i}(t)=\\sigma(\\boldsymbol{\\hat{i}}(t))$となります。すると、これを用いると、\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "    \\boldsymbol{\\hat{i}}(t)\\\\\n",
    "    \\boldsymbol{\\hat{o}}(t)\\\\\n",
    "    \\boldsymbol{\\hat{f}}(t)\\\\\n",
    "    \\boldsymbol{\\hat{a}}(t)\n",
    "\\end{array}\n",
    "\\right)\n",
    "=\n",
    "\\left(\n",
    "\\begin{array}{ccc}\n",
    "    \\boldsymbol{W_i} & \\boldsymbol{U_i} & \\boldsymbol{b_i}\\\\\n",
    "    \\boldsymbol{W_o} & \\boldsymbol{U_o} & \\boldsymbol{b_o}\\\\\n",
    "    \\boldsymbol{W_f} & \\boldsymbol{U_f} & \\boldsymbol{b_f}\\\\\n",
    "    \\boldsymbol{W_a} & \\boldsymbol{U_a} & \\boldsymbol{b_a}\\\\\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "    \\boldsymbol{x}(t)\\\\\n",
    "    \\boldsymbol{h}(t-1)\\\\\n",
    "    \\boldsymbol{1}\n",
    "\\end{array}\n",
    "\\right)\\tag{1.5}\n",
    "$$\n",
    "\n",
    "と書くことができます。更にこれを\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\widehat{gates}}(t) = \\boldsymbol{\\widehat{W}}\\boldsymbol{\\widehat{x}}(t) \\tag{1.6}\n",
    "$$\n",
    "のようにまとめて書くことにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題１】**　LSTMのパラメータを初期化する関数を用意します。\n",
    "\n",
    "前置きが長くなりましたが、numpyで計算するときもですし、GPU上で計算するときもこのようにまとめることにより効率よく計算できます。なので、LSTMは１２個パラーメータ（重み８個、バイアス４個）が存在しますが、式(1.6)に従って１つのように扱います。\n",
    "\n",
    "関数`LSTM_init_parameters`は引数として、\n",
    "- n_input: 入力の次元\n",
    "- n_hidden: 隠れ層のユニット数\n",
    "\n",
    "があります。この関数内では式(1.6)に従って`W`を初期化します。バイアスは０で初期化しますが、まずは`glorot_uniform`で一括でランダムに初期化した後にバイアスの箇所のみ0に置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber20 0849a33a688d3113abe78ba50ab337e3\n",
    "def LSTM_init_parameters(n_input, n_hidden):\n",
    "    ###############START CODE HERE###############\n",
    "    # 式(1.6)に従って重みをすべてまとめて初期化\n",
    "    W = glorot_uniform(shape = (n_input + n_hidden + 1, n_hidden * 4))\n",
    "    ################END CODE HERE################\n",
    "    W[-1] = 0 #バイアスはゼロに初期化\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 20 Step5_07.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMの順伝播の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題２】**　LSTMの順伝播を実装します。\n",
    "\n",
    "LSTMの順伝播は式(1.1)~(1.6)に加えて下式を計算します。\n",
    "\n",
    "$\n",
    "\\boldsymbol{c}(t) = \\boldsymbol{i}(t)\\odot \\boldsymbol{a}(t)+\\boldsymbol{f}(t)\\odot \\boldsymbol{c}(t-1)\\tag{1.7}\n",
    "$\n",
    "\n",
    "\n",
    "$\n",
    "\\boldsymbol{h}(t) = \\boldsymbol{o}(t)\\odot g(\\boldsymbol{c}(t))\\tag{1.8}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "関数`LSTM_forward`は４つの引数があります。\n",
    "- X: 入力（データ長、ミニバッチサイズ、入力サイズ）\n",
    "- W: `LSTM_init_parameters`から得られる重み\n",
    "- c0, h0: LSTMのCECと隠れ層の値（なければゼロで初期化）\n",
    "\n",
    "ここで実装していただく箇所の説明をします。\n",
    "- `ones`: 式(1.5)の最後の1を作成します。形は(ミニバッチサイズ、１)です。\n",
    "- `x_h`: 式(1.6)の$\\hat{\\boldsymbol{x}}(t)$を作成します。ここでは[np.hstack](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.hstack.html)を用います。[np.concatenate](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.concatenate.html)でも可能ですがこの際はaxisの指定が必要です。\n",
    "- `gates_h`: 式(1.6)の$\\boldsymbol{\\widehat{gates}}(t)$を計算します。\n",
    "- `i_h, o_h, f_h, a_h`: [np.split](https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html)を用いて、$\\boldsymbol{\\widehat{gates}}(t)$を分離します。\n",
    "- `i, o, f, a`: 式(1.1)~(1.4)を計算します。\n",
    "- `c`: 式(1.7)を計算します。\n",
    "- `ct`: 式(1.8)の$g(\\boldsymbol{c}(t))$の箇所をまず計算します。\n",
    "- `h`: 式(1.8)を計算します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber21 32a83f2a4e56fe6eb6d3d4614764ad63\n",
    "def LSTM_forward(X, W, c0 = None, h0 = None):\n",
    "    # パラメータを取得\n",
    "    length, batch_size, n_input = X.shape\n",
    "    n_hidden = W.shape[1]//4\n",
    "    n_input = W.shape[0] - n_hidden - 1\n",
    "    \n",
    "    # c0, h0の指定がない場合ゼロで初期化\n",
    "    if c0 is None: c0 = np.zeros((batch_size, n_hidden))\n",
    "    if h0 is None: h0 = np.zeros((batch_size, n_hidden))\n",
    "    \n",
    "    # 各ステップの状態を保存しておくための配列\n",
    "    X_h = np.zeros((length, batch_size, W.shape[0]))\n",
    "    H = np.zeros((length, batch_size, n_hidden))\n",
    "    Gates = np.zeros((length, batch_size, n_hidden*4))\n",
    "    C = np.zeros((length, batch_size, n_hidden))\n",
    "    Ct = np.zeros((length, batch_size, n_hidden))\n",
    "    \n",
    "    for t in range(length):\n",
    "        # 式(1.5)や式(1.7)にあるh(t-1), c(t-1)\n",
    "        prevh = H[t-1] if t > 0 else h0\n",
    "        prevc = C[t-1] if t > 0 else c0\n",
    "        x = X[t]\n",
    "        ###############START CODE HERE###############\n",
    "        ones = np.ones((batch_size, 1))\n",
    "        x_h = np.hstack([x, prevh, ones])\n",
    "        gates_h = np.dot(x_h, W)\n",
    "        i_h, o_h, f_h, a_h =np.split(gates_h, 4, axis = 1)\n",
    "        \n",
    "        i = sigmoid(i_h)\n",
    "        o = sigmoid(o_h)\n",
    "        f = sigmoid(f_h)\n",
    "        a = tanh(a_h)\n",
    "        \n",
    "        c = i * a + f * prevc\n",
    "        ct = tanh(c)       \n",
    "        h = o * ct\n",
    "        ################END CODE HERE################\n",
    "        # 状態を保存\n",
    "        X_h[t] = x_h\n",
    "        Gates[t] = np.concatenate([i, o, f, a], axis=1)\n",
    "        C[t] = c\n",
    "        Ct[t] = ct\n",
    "        H[t] = h\n",
    "\n",
    "    cache = {}\n",
    "    cache['W'] = W\n",
    "    cache['X_h'] = X_h\n",
    "    cache['Gates'] = Gates\n",
    "    cache['C'] = C\n",
    "    cache['Ct'] = Ct\n",
    "    cache['H'] = H\n",
    "    cache['c0'] = c0\n",
    "    cache['h0'] = h0\n",
    "\n",
    "    return H, cache, C[t], H[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 21 Step5_07.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの順伝播を実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_last = \n",
      " [[ 0.06783421  0.11366456  0.06664872]\n",
      " [ 0.08703627 -0.07033305  0.00861095]\n",
      " [-0.0500864   0.01666135  0.01540065]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "n_input, n_hidden = 2, 3\n",
    "W = LSTM_init_parameters(n_input,n_hidden)\n",
    "batch_size, length = 3, 12\n",
    "\n",
    "sample_X = rng.randn(length, batch_size, n_input)\n",
    "H, cache_LSTM, c_last, H_last  = LSTM_forward(sample_X, W)\n",
    "print('H_last = \\n', H_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "H_last = \n",
    "\n",
    " [[ 0.06783421  0.11366456  0.06664872]\n",
    " \n",
    " [ 0.08703627 -0.07033305  0.00861095]\n",
    " \n",
    " [-0.0500864   0.01666135  0.01540065]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMの逆伝播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここにはLSTMの逆伝播の関数があります。LSTMの逆伝播自体はこれまでのRNNとさほど変わりはないのですが、コードにするとややわかりにくくなるので、実装はしません。ただ、一度この関数内でどのような計算を行っているのか見てみてください。\n",
    "\n",
    "関数`LSTM_backward`は４つの引数があります。\n",
    "- `dprev`: 上の層からの勾配\n",
    "- `cache`: 順伝播で保存しておいたキャッシュ\n",
    "- `dcn, dhn`: CECや隠れ状態に勾配がすでにある場合に使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_backward(dprev, cache, dcn = None, dhn = None): \n",
    "    # 順伝播の時のキャッシュを取得\n",
    "    W = cache['W']\n",
    "    X_h = cache['X_h']\n",
    "    Gates = cache['Gates']\n",
    "    C = cache['C']\n",
    "    Ct = cache['Ct']\n",
    "    H = cache['H']\n",
    "    c0 = cache['c0']\n",
    "    h0 = cache['h0']\n",
    "    \n",
    "    # パラメータを取得\n",
    "    length, batch_size, n_hidden = H.shape\n",
    "    n_input = W.shape[0] - n_hidden - 1\n",
    "\n",
    "    # 勾配を格納するための配列\n",
    "    dW = np.zeros_like(W)\n",
    "    dC = np.zeros_like(C)\n",
    "    dX = np.zeros((length,batch_size,n_input))\n",
    "    \n",
    "    # dprevを書き換えないようにコピー\n",
    "    dH = dprev.copy()\n",
    "    # dcn, dhnがある場合は予め勾配を足しておく\n",
    "    if dcn is not None: dC[-1] += dcn.copy()\n",
    "    if dhn is not None: dH[-1] += dhn.copy()\n",
    "    \n",
    "    for t in reversed(range(length)):\n",
    "        # ゲートなどを取得\n",
    "        i, o, f, a = np.hsplit(Gates[t], 4) \n",
    "        \n",
    "        # dL/do = dL/dh * dh/do : batckprop through output-gate\n",
    "        do = Ct[t] * dH[t]\n",
    "        # dL/dc = dL/dh * dh/dct * dct/dc = dh[t] * o * (1-tanhCt**2)\n",
    "        dC[t] += dtanh(Ct[t]) * (o * dH[t])\n",
    "        \n",
    "        if t > 0:\n",
    "            # dL/df = dL/dc * dc/df : backprop through forget_gate\n",
    "            df = C[t-1] * dC[t]\n",
    "            # dL/dc(t-1) = dL/dc * dc/dc(t-1)\n",
    "            dC[t-1] += f * dC[t]\n",
    "        else:\n",
    "            # dL/df = dL/dc * dc/df : backprop through forget_gate\n",
    "            df = c0 * dC[t]\n",
    "            # dL/dc(t-1) = dL/dc * dc/df\n",
    "            dc0 = f * dC[t]\n",
    "            \n",
    "        # dL/di = dL/dc * dc/da\n",
    "        di = a * dC[t]        \n",
    "        # dL/da = dL/dc * dc/da\n",
    "        da = i * dC[t]\n",
    "\n",
    "        # dL/gates = dL/dGates * dGates/gates (gates=(i_hat, o_hat, f_hat))\n",
    "        di_hat = dsigmoid(i) * di\n",
    "        do_hat = dsigmoid(o) * do\n",
    "        df_hat = dsigmoid(f) * df\n",
    "        # dL/a_hat = dL/da * da/a_hat\n",
    "        da_hat = dtanh(a) * da\n",
    "        \n",
    "        dgates_h = np.concatenate((di_hat, do_hat, df_hat, da_hat), axis=1)\n",
    "\n",
    "        # dL/dW = dL/dgates * dgates/dW\n",
    "        dW += np.dot(X_h[t].T, dgates_h)\n",
    "        \n",
    "        # dL/dh_in = dL/dgates_h * dgates_h/dh_in\n",
    "        dx_h = np.dot(dgates_h, W.T)\n",
    "\n",
    "        # dL/dX\n",
    "        dX[t] = dx_h[:,:n_input]\n",
    "        if t > 0:\n",
    "            # dL/dh(t-1)\n",
    "            dH[t-1] += dx_h[:,n_input:-1]\n",
    "        else:\n",
    "            dh0 = dx_h[:,n_input:-1]\n",
    "\n",
    "    return dX, dW, dc0, dh0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMの逆伝播を実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh0 = \n",
      " [[ 0.12472003  0.12491856  0.04649688]\n",
      " [-0.01681211  0.19066373 -0.10475641]\n",
      " [-0.16024844  0.06606487  0.17958243]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "wrand = rng.randn(*H.shape)\n",
    "dH = wrand\n",
    "dX, dparams, dc0, dh0 = LSTM_backward(dH, cache_LSTM)\n",
    "print('dh0 = \\n',dh0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "dh0 = \n",
    "\n",
    "[[ 0.12472003  0.12491856  0.04649688]\n",
    "\n",
    "[-0.01681211  0.19066373 -0.10475641]\n",
    "\n",
    "[-0.16024844  0.06606487  0.17958243]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMの勾配チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**【課題３】**　LSTMの逆伝播をチェックするコードを作成します。\n",
    "\n",
    "NNやCNNそしてRNNにおいて勾配計算を実装する際に、コードエラーが、なくて一見学習も進んでいるように見えても実は勾配計算でミスを犯している、などということは多々あります。そこで、連鎖率を使って計算した勾配と数値微分の値が一致するか確認する必要があります。ここでは実際にこれらが一致しているか勾配チェックを通して確かめます。\n",
    "\n",
    "数値微分とは、\n",
    "$$\n",
    "\\frac{dJ(\\theta)}{d\\theta} =  \\lim_{\\epsilon\\to 0} \n",
    "\\frac{J(\\theta+\\epsilon) - J(\\theta-\\epsilon)}{2\\epsilon}\\tag{1.9}\n",
    "$$\n",
    "で計算できます。ここではLSTMのパラメータの値１つずつ微小変化を加え、数値微分を求め実装した勾配計算との誤差を見ます。ここで注意すべき点はパラメータ$\\boldsymbol{W_i}$に微小変化を加えるのではなく、$\\boldsymbol{W_i}$の中の１つの値に微小変化を加えます。$\\boldsymbol{W_i}$が3×4の行列だとしたら１２回数値微分を行い、その都度勾配をチェックします。コードではこれが２つ目のforループに当たります。\n",
    "\n",
    "上式を使って数値微分を求めたら最後に実装した勾配との差を見ます。ただこの時に数値微分の値そのものが大きいあるいは小さいこともあるので、比較ができるように誤差を数値微分と勾配を足し合わせた値で割ります。コードでは`rel_error`に当たります。この値が$10^{-10}$よりも小さければ勾配計算はほとんどの場合あっています。値が大きい場合は勾配計算が間違っている（今回は実装していないのでありえません）か、勾配チェックのコードが間違っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX: 2.850e-11\n",
      "dW: 1.376e-11\n",
      "dc0: 6.193e-11\n",
      "dh0: 1.201e-11\n"
     ]
    }
   ],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber22 ffbb1c4eec11b54c652979689f5d2594\n",
    "rng = np.random.RandomState(1234)\n",
    "epsilon = 1e-5\n",
    "\n",
    "# パラメータを初期化\n",
    "n_input, n_hidden = 2, 3\n",
    "batch_size, length = 3, 12\n",
    "params = LSTM_init_parameters(n_input, n_hidden)\n",
    "X = rng.randn(length,batch_size,n_input)\n",
    "c0 = rng.randn(batch_size,n_hidden)\n",
    "h0 = rng.randn(batch_size,n_hidden)\n",
    "\n",
    "# 順伝播（*_とするとそれ以降の返り値と１つのタプルに格納、返り値を破棄する場合に便利）\n",
    "H, cache, *_  = LSTM_forward(X, params, c0=c0, h0=h0)\n",
    "# 順伝播の出力とrandomYをかけて足したものを損失とする\n",
    "randomY = rng.randn(*H.shape) # 正解ラベル的なもの\n",
    "loss = np.sum(H * randomY)\n",
    "# dloss/dH = randomY\n",
    "dH = randomY\n",
    "# 逆伝播\n",
    "dX, dW, dc0, dh0 = LSTM_backward(dH, cache)\n",
    "\n",
    "variables = (X, params, c0, h0)\n",
    "grads_analytic = (dX, dW, dc0, dh0)\n",
    "names = ('dX', 'dW', 'dc0', 'dh0')\n",
    "for j in range(len(variables)):\n",
    "    mat = variables[j]\n",
    "    dmat = grads_analytic[j]\n",
    "    name = names[j]\n",
    "    max_rel_error = 0\n",
    "    for i in range(mat.size):\n",
    "        ###############START CODE HERE###############\n",
    "        # theta + epsilon\n",
    "        mat.flat[i] += epsilon\n",
    "        # 順伝播を計算\n",
    "        H, *_ = LSTM_forward(X, params, c0=c0, h0=h0)\n",
    "        loss1 = np.sum(H * randomY)\n",
    "\n",
    "        # theta - epsilon、一つ前で+epsilonしているのでここでは-epsilon*2とする。\n",
    "        mat.flat[i] -= epsilon * 2\n",
    "        H, *_ = LSTM_forward(X, params, c0=c0, h0=h0)\n",
    "        loss2 = np.sum(H * randomY)\n",
    "\n",
    "        # 元に戻す\n",
    "        mat.flat[i] += epsilon\n",
    "        \n",
    "        # 数値微分\n",
    "        grad_numerical = (loss1 - loss2) / (2 * epsilon)\n",
    "        ################END CODE HERE################\n",
    "        \n",
    "        # 解析的に求めた微分\n",
    "        grad_analytic = dmat.flat[i]\n",
    "        \n",
    "        # gradそのものが大きいあるいは小さい可能性があるので、相対的な誤差を計算\n",
    "        rel_error = abs(grad_analytic - grad_numerical) / abs(grad_numerical + grad_analytic)\n",
    "    if rel_error > max_rel_error: # 最大の誤差を保存\n",
    "        max_rel_error = rel_error\n",
    "    print('{}: {:.3e}'.format(name, max_rel_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExcessiveAccess: Wait for 10 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 22 Step5_07.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRUの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUは以下の式計算できます。ここで$\\boldsymbol{z}(t)$は更新ゲート、$\\boldsymbol{r}(t)$はリセットゲートです。LSTMとは違いゲートは２つしかありません。なので、パラメータもLSTMの１２個と比べて９個少なくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\boldsymbol{z}(t)=\\sigma(\\boldsymbol{W_z}\\boldsymbol{x}(t)+\\boldsymbol{U_z}\\boldsymbol{h}(t-1)+\\boldsymbol{b_z}) \\tag{2.1}\n",
    "$\n",
    "\n",
    "$\n",
    "\\boldsymbol{r}(t)=\\sigma(\\boldsymbol{W_r}\\boldsymbol{x}(t)+\\boldsymbol{U_r}\\boldsymbol{h}(t-1)+\\boldsymbol{b_r}) \\tag{2.2}\n",
    "$\n",
    "\n",
    "$\n",
    "\\boldsymbol{\\tilde{h}}(t)=f(\\boldsymbol{W_h}\\boldsymbol{x}(t) + \\boldsymbol{U_h}(\\boldsymbol{r}(t)\\odot \\boldsymbol{h}(t-1))+\\boldsymbol{b_h}) \\tag{2.3}\n",
    "$\n",
    "$\n",
    "%\\boldsymbol{h}(t)=\\boldsymbol{z}(t)\\odot\\boldsymbol{h}(t-1) + (1-\\boldsymbol{z}(t))\\odot\\boldsymbol{\\tilde{h}}(t) \\tag{2.4}\n",
    "$\n",
    "$\n",
    "\\boldsymbol{h}(t)=(1-\\boldsymbol{z}(t))\\odot\\boldsymbol{h}(t-1) + \\boldsymbol{z}(t)\\odot\\boldsymbol{\\tilde{h}}(t) \\tag{2.4}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRUのパラメータの初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 【課題４】 **　GRUの順伝播を実装します。\n",
    "\n",
    "\n",
    "まずはGRUのパラメータを初期化します。式(2.1)と式(2.2)はまとめて計算することはできるのですが、今回は可読性を優先して、LSTMの時はまとめて初期化しましたが、ここでは別々に初期化します。\n",
    "\n",
    "関数`GRU_init_parameters`の引数はLSTMと同様に\n",
    "- n_input: 入力の次元\n",
    "- n_hidden: 隠れ層のユニット数\n",
    "です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber23 233106a68106cadf77d0d19fd8a3fef3\n",
    "def GRU_init_parameters(n_input, n_hidden):\n",
    "    ###############START CODE HERE###############\n",
    "    Wr = glorot_uniform((n_input, n_hidden))\n",
    "    Wz = glorot_uniform((n_input, n_hidden))\n",
    "    Wh = glorot_uniform((n_input, n_hidden))\n",
    "    Ur = glorot_uniform((n_hidden, n_hidden))\n",
    "    Uz = glorot_uniform((n_hidden, n_hidden))\n",
    "    Uh = glorot_uniform((n_hidden, n_hidden))\n",
    "    br = np.zeros((n_hidden))\n",
    "    bz = np.zeros((n_hidden))\n",
    "    bh = np.zeros((n_hidden))\n",
    "    ################END CODE HERE################\n",
    "    W = (Wr, Wz, Wh, Ur, Uz, Uh) \n",
    "    b = (br, bz, bh)\n",
    "    return (W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 23 Step5_07.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRUの順伝播の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 【課題５】 **　次にGRUの順伝播を実装します。\n",
    "\n",
    "関数`GRU_forward`は３つの引数があります。\n",
    "- X: 入力（データ長、ミニバッチサイズ、入力サイズ）\n",
    "- W: `LSTM_init_parameters`から得られる重み\n",
    "- h0: 隠れ層の値（なければゼロで初期化）\n",
    "\n",
    "ここで実装していただく箇所は式(2.1)~(2.4)に対応する箇所です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber24 c07ed3ce024b9e7a572750e8a33888c5\n",
    "def GRU_forward(X, params, h0 = None):\n",
    "    Wr, Wz, Wh, Ur, Uz, Uh = params[0]\n",
    "    br, bz, bh = params[1]\n",
    "    length, batch_size, n_input = X.shape\n",
    "    n_input = Wr.shape[0]\n",
    "    n_hidden = Ur.shape[0]\n",
    "    \n",
    "    if h0 is None: h0 = np.zeros((batch_size, n_hidden))\n",
    "        \n",
    "    R = np.zeros((length, batch_size, n_hidden))\n",
    "    Z = np.zeros((length, batch_size, n_hidden))\n",
    "    H_hat = np.zeros((length, batch_size, n_hidden))\n",
    "    H = np.zeros((length, batch_size, n_hidden))\n",
    "    \n",
    "    for t in range(length):\n",
    "        h_prev = H[t-1] if t > 0  else h0\n",
    "        x = X[t]\n",
    "        ###############START CODE HERE###############\n",
    "        # 式(2.1)\n",
    "        z = sigmoid(np.dot(x, Wz) + np.dot(H[t-1], Uz) + bz)\n",
    "        # 式(2.2)\n",
    "        r = sigmoid(np.dot(x, Wr) + np.dot(H[t-1], Ur) + br)\n",
    "        # 式(2.3)\n",
    "        h_hat = tanh(np.dot(x, Wh) + np.dot(r * H[t-1], Uh) + bh)\n",
    "        # 式(2.4)\n",
    "        h_next = (1 - z) * H[t-1] + z * h_hat\n",
    "        ################END CODE HERE################\n",
    "        Z[t] = z\n",
    "        R[t] = r\n",
    "        H_hat[t] = h_hat\n",
    "        H[t] = h_next\n",
    "\n",
    "    cache = {}\n",
    "    cache['params'] = params\n",
    "    cache['X'] = X\n",
    "    cache['Z'] = Z\n",
    "    cache['R'] = R\n",
    "    cache['H_hat'] = H_hat\n",
    "    cache['H'] = H\n",
    "    cache['h0'] = h0\n",
    "\n",
    "    return H, cache, H[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 24 Step5_07.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUの順伝播を実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_last = \n",
      " [[ 0.2176545  -0.00864095  0.4214221 ]\n",
      " [ 0.12158509  0.34806795 -0.02168339]\n",
      " [ 0.47930925  0.23608282  0.15999168]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "n_input, n_hidden = 2, 3\n",
    "params = GRU_init_parameters(n_input,n_hidden)\n",
    "batch_size, length = 3, 12\n",
    "\n",
    "sample_X = rng.randn(length, batch_size, n_input)\n",
    "H, cache_GRU, H_last = GRU_forward(sample_X, params)\n",
    "print('H_last = \\n', H_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "H_last = \n",
    "\n",
    " [[ 0.2176545  -0.00864095  0.4214221 ]\n",
    " \n",
    " [ 0.12158509  0.34806795 -0.02168339]\n",
    " \n",
    " [ 0.47930925  0.23608282  0.15999168]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRUの逆伝播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここにはGRUの逆伝播の関数があります。ここでも逆伝播は実装していただきません。\n",
    "\n",
    "関数`GRU_backward`は４つの引数があります。\n",
    "- `dprev`: 上の層からの勾配\n",
    "- `cache`: 順伝播で保存しておいたキャッシュ\n",
    "- `dhn`: 隠れ状態に勾配がすでにある場合に使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GRU_backward(dprev, cache, dhn = None):\n",
    "    params = cache['params']\n",
    "    X = cache['X']\n",
    "    R = cache['R']\n",
    "    Z = cache['Z']\n",
    "    H_hat = cache['H_hat']\n",
    "    H = cache['H']\n",
    "    h0 = cache['h0'] \n",
    "    \n",
    "    Wr, Wz, Wh, Ur, Uz, Uh = params[0]\n",
    "    br, bz, bh = params[1]\n",
    "    length, batch_size, n_input = X.shape\n",
    "    n_input = Wr.shape[0]\n",
    "    n_hidden = Ur.shape[0]\n",
    "    \n",
    "    dW_ih = np.zeros((n_input, 3*n_hidden))\n",
    "    dW_hh = np.zeros((n_hidden, 3*n_hidden))\n",
    "    dbias = np.zeros((n_hidden*3))\n",
    "    dWr, dWz, dWh = np.split(dW_ih, 3, axis=1)\n",
    "    dUr, dUz, dUh = np.split(dW_hh, 3, axis=1)\n",
    "    dbr, dbz, dbh = np.split(dbias, 3, axis=0)\n",
    "    dX = np.zeros((length,batch_size,n_input))\n",
    "    dprev = np.copy(dprev)\n",
    "    for t in reversed(range(length)):\n",
    "        z = Z[t]\n",
    "        dh = dprev[t]\n",
    "        h_prev = H[t-1] if t > 0 else h0\n",
    "        h_hat = H_hat[t]\n",
    "        r = R[t]\n",
    "        x = X[t]\n",
    "        ### 勾配計算 ###\n",
    "        dz = (h_hat-h_prev) * dh\n",
    "        dh_prev = (1-z) * dh\n",
    "        dh_hat = z * dh\n",
    "        \n",
    "        dh_hat_h = dtanh(h_hat) * dh_hat\n",
    "        dWh += np.dot(x.T, dh_hat_h)\n",
    "        dx  = np.dot(dh_hat_h, Wh.T)\n",
    "        dUh += np.dot((r*h_prev).T, dh_hat_h)\n",
    "        dr = h_prev * np.dot(dh_hat_h, Uh.T)\n",
    "        dh_prev += r * np.dot(dh_hat_h, Uh.T)\n",
    "        dbh += np.sum(dh_hat_h, axis=0)\n",
    "        \n",
    "        dr_h = dsigmoid(r) * dr\n",
    "        dWr += np.dot(x.T, dr_h)\n",
    "        dx += np.dot(dr_h, Wr.T)\n",
    "        dUr += np.dot(h_prev.T, dr_h)\n",
    "        dh_prev += np.dot(dr_h, Ur.T)\n",
    "        dbr += np.sum(dr_h, axis=0)\n",
    "                      \n",
    "        dt = dsigmoid(z) * dz\n",
    "        dWz += np.dot(x.T, dt)\n",
    "        dx += np.dot(dt, Wz.T)\n",
    "        dUz += np.dot(h_prev.T, dt)\n",
    "        dh_prev += np.dot(dt, Uz.T)\n",
    "        dbz += np.sum(dt, axis=0)\n",
    "\n",
    "        dX[t] = dx\n",
    "        if t > 0:\n",
    "            dprev[t-1] += dh_prev\n",
    "        else:\n",
    "            dh0 = dh_prev\n",
    "        ############\n",
    "    dparams = (dWr, dWz, dWh, dUr, dUz, dUh, dbr, dbz, dbh)\n",
    "    return dX, dparams, dh0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dh0 = \n",
      " [[-1.29291966 -1.03813569  1.53903238]\n",
      " [ 0.40343046 -1.57202558  0.64777347]\n",
      " [-0.03634266 -0.18345031  0.05864957]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "wrand = rng.randn(*H.shape)\n",
    "dH = wrand\n",
    "dX, dparams,dh0 = GRU_backward(dH, cache_GRU)\n",
    "print('dh0 = \\n',dh0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "dh0 = \n",
    "\n",
    " [[-1.29291966 -1.03813569  1.53903238]\n",
    " \n",
    " [ 0.40343046 -1.57202558  0.64777347]\n",
    " \n",
    " [-0.03634266 -0.18345031  0.05864957]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRUの勾配チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 【課題６】 **　GRUの逆伝播をチェックするコードを作成します。\n",
    "\n",
    "LSTMの時とほぼ同じですが、もう一度勾配チェックのコードを実装してください。実装していただく箇所でLSTMの時と異なる箇所はLSTM_forwardとその引数だけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX: 2.199e-11\n",
      "dWr: 7.964e-02\n",
      "dWz: 2.711e-03\n",
      "dWh: 1.314e-10\n",
      "dUr: 1.149e+00\n",
      "dUz: 2.083e-01\n",
      "dUh: 2.388e-02\n",
      "dbr: 2.760e-01\n",
      "dbz: 5.562e-02\n",
      "dbh: 5.521e-12\n",
      "dh0: 1.000e+00\n"
     ]
    }
   ],
   "source": [
    "#Coursedele-02 Step5 QuestionNumber25 255fd4ffe650359e8d9571a1e13b41d0\n",
    "rng = np.random.RandomState(1234)\n",
    "epsilon = 1e-5\n",
    "\n",
    "# パラメータを初期化\n",
    "n_input, n_hidden = 2, 3\n",
    "batch_size, length = 3, 12\n",
    "params = GRU_init_parameters(n_input, n_hidden)\n",
    "X = rng.randn(length,batch_size,n_input)\n",
    "h0 = rng.randn(batch_size,n_hidden)\n",
    "\n",
    "# 順伝播\n",
    "H, cache, Ht = GRU_forward(X, params, h0=h0)\n",
    "# 順伝播の出力とrandomYをかけて足したものを損失とする\n",
    "randomY = rng.randn(*H.shape)\n",
    "loss = np.sum(H * randomY)\n",
    "# dloss/dH = randomY\n",
    "dH = randomY\n",
    "# 逆伝播\n",
    "dX, dparams, dh0 = GRU_backward(dH, cache)\n",
    "\n",
    "variables = (X,) + params[0] + params[1] + (h0,)\n",
    "grads_analytic = (dX, ) + dparams + (dh0,)\n",
    "names = ['dX', 'dWr', 'dWz', 'dWh', \n",
    "         'dUr', 'dUz', 'dUh', \n",
    "         'dbr', 'dbz', 'dbh', 'dh0']\n",
    "for j in range(len(variables)):\n",
    "    mat = variables[j]\n",
    "    dmat = grads_analytic[j]\n",
    "    name = names[j]\n",
    "    max_rel_error = 0\n",
    "    for i in range(mat.size):\n",
    "        ###############START CODE HERE###############\n",
    "        # theta + epsilon\n",
    "        mat.flat[i] += epsilon\n",
    "        H, *_ = GRU_forward(X, params, h0=h0)\n",
    "        loss1 = np.sum(H * randomY)\n",
    "\n",
    "        # theta - epsilon、一つ前で+epsilonしているのでここでは-epsilon*2とする。\n",
    "        mat.flat[i] -= 2 * epsilon\n",
    "        H, *_ = GRU_forward(X, params, h0=h0)\n",
    "        loss2 = np.sum(H * randomY)\n",
    "\n",
    "        # 元に戻す\n",
    "        mat.flat[i] += epsilon\n",
    "        # 数値微分\n",
    "        grad_numerical = (loss1 - loss2) / (2 * epsilon)\n",
    "        ################END CODE HERE################\n",
    "        \n",
    "        # 解析的に求めた微分\n",
    "        grad_analytic = dmat.flat[i]\n",
    "        \n",
    "        # gradそのものが大きいあるいは小さい可能性があるので、相対的な誤差を計算\n",
    "        rel_error = abs(grad_analytic - grad_numerical) / abs(grad_numerical + grad_analytic)\n",
    "    if rel_error > max_rel_error: # 最大の誤差を保存\n",
    "        max_rel_error = rel_error\n",
    "    print('{}: {:.3e}'.format(name, max_rel_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ファイルを保存後 **、次のセルを実行（Shift+Enter）で採点を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX: 6.062e-12\n",
      "dWr: 2.266e-11\n",
      "dWz: 1.337e-12\n",
      "dWh: 5.007e-11\n",
      "dUr: 1.858e-10\n",
      "dUz: 3.232e-11\n",
      "dUh: 1.496e-10\n",
      "dbr: 1.032e-10\n",
      "dbz: 4.520e-11\n",
      "dbh: 2.992e-11\n",
      "dh0: 1.186e-11\n",
      "Congratulations!\n",
      "We give you 10 points out of 10 points.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./validation_client.py dele-02 5 25 Step5_07.ipynb api.internal.zero2one.jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "261px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
